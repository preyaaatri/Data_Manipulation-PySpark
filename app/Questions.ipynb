{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding Challenges\n",
    "\n",
    "There are three problems, below, with mandatory tool usage, in parentheses.  Try to complete two of the three problems.  No points are awarded for completion of a third problem. \n",
    "    \n",
    "1. Data Manipulation (SparkSQL)\n",
    "2. Data Vizualization (Vue, React)\n",
    "3. Data Models (Traditional, Neural Network)\n",
    "    \n",
    "<br>\n",
    "\n",
    "### Instructions\n",
    "\n",
    "* Copy this Jupyter notebook and use it as your turn-in report\n",
    "  - there may be multiple notebooks, if a different kernel is used for different tasks\n",
    "  - this does not apply to the Data Vizualization task, which should be a zip file\n",
    "* Notebook should, at least:\n",
    "  - describe the work you've done using markdown (styled as any professional report)\n",
    "  - investigate the data and state your assumptions\n",
    "  - state results and future work\n",
    "  - idempotent - clean up after yourself (i.e. drop your tables)\n",
    "* Notebook is scored based upon:\n",
    "  - good problem-solving workflow\n",
    "  - quality of code\n",
    "  - explanation of operations performed beneath code\n",
    "  - reproduceability and documentation\n",
    "  - professional, interesting, and witty text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<hr>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Manipulation (SparkSQL)\n",
    "\n",
    "Use Apache Spark to import the data: `./Data/classification/DM-classification.json`\n",
    "\n",
    "\n",
    "While you MUST use Apache Spark to answer this Data Manipulation question, ANY language (Scala, Pyspark, SparklyR) can be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure your environment\n",
    "\n",
    "Please explain this configuration, and why you chose it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETL\n",
    "\n",
    "Load the data into a Spark-SQL dataframe with the folowing columns: 'content','label','size','usage','effect','date'.  Create a Temporary Table for querying.  \n",
    "\n",
    "Ensure you use appropriate types with your schema using: StructField, StructType."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process\n",
    "\n",
    "Group the table by 'size', and sort based on 'date'.  Then, create a new column that is the difference between 'date' in consecutive records (within groups)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save\n",
    "\n",
    "Save the data results as one file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<hr>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Visualization (Vue, React)\n",
    "\n",
    "Design and build a User Interface to visualize the data: `./Data/classification/DV-classification.json`\n",
    "\n",
    "\n",
    "Please be creative in your design, but meet the following requirements:\n",
    "\n",
    "* enable it to be deployed using docker: `docker run`\n",
    "* use either Vue, React, or complimentary framework (ie. Nuxt, Next)\n",
    "* use a styling library of your choice\n",
    "* add some basic interactivity to explore the data, such as [dc.js](https://dc-js.github.io/dc.js/)\n",
    "* explain how this would be deployed, including the necessary tools and hardware\n",
    "\n",
    "Send this solution via a zipped directory, and include instructions.\n",
    "\n",
    "![example interface](./Data/classification/image-DimChart.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<hr>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Models\n",
    "\n",
    "__Note:__ this task is language and framework agnostic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models: Traditional Methods\n",
    "\n",
    "This section will make use of traditional analytic methods to describe and model the data.  It will NOT make use of Neural Network - based methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data and summarize\n",
    "\n",
    "Import the classification data: `./Data/classification/classification.txt` into two columns: 'content', 'labels'.  Review and summarize the data.  Make any notes of your observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "Create preprocessing function that does the following:\n",
    "    \n",
    "* lowercase text\n",
    "* replace punctuation, digits, & all special characters except '_' underscore with one space\n",
    "\n",
    "Preprocess 'content' column, and store prepped content in a new column called 'prep_content'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset dev(train, validate)-test split\n",
    "\n",
    "Make dev_train, dev_validate, and test sets with dev_validate and test sets being the same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named Entity Recognition\n",
    "\n",
    "Count how many organizations -- 'ORG' exist in the `dev_train` dataset.  Use a text processing framework with included NER classifier to perform this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML pipeline with logistic regression\n",
    "\n",
    "Build a ML Pipeline that performs the following:\n",
    "\n",
    "* vectorizes text\n",
    "* selects top 100 features with chi2\n",
    "* trains a logistic regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline inspection\n",
    "\n",
    "Review the pipeline and print the 100 features that the chi2 selector chose along with each feature's score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model \n",
    "\n",
    "Plot the learning curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discuss future work\n",
    "\n",
    "Make notes of the learning curve and discuss how it effects your future work in this modeling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models: Neural Network Methods\n",
    "\n",
    "This section will make use of Neural Network - based methods, including word embeddings.  You MUST use a neural network (NN) framework (PyTorch, DeepLearning4J, MXNet, Keras, TensorFlow, etc) for performing these tasks.\n",
    "\n",
    "While you will not be judged on the accuracy of the model, the architecture should be appropriate for the situation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure environment\n",
    "\n",
    "Prepare your environment for your NN framwork of choice, and with the ability to reproduce your results.\n",
    "\n",
    "Also, explain your platform and how different hardware might provide improvements to your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-ETL and dataset split\n",
    "\n",
    "Reformat the original data for ingestion with your NN framework.  Be sure to explain how the process relates to your framework.\n",
    "\n",
    "Ensure that you re-split the data, also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word embeddings\n",
    "\n",
    "Apply word embedding and explain their purpose with respect to the traditional methods used, above.\n",
    "\n",
    "Explain the underlying concepts of word embeddings with an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model architecture\n",
    "\n",
    "Determine an architecture for your neural network classifier.  Explain why you chose the architecture, then implement it in your chosen framework.\n",
    "\n",
    "Be sure to initialize the model, and print the number of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training routine\n",
    "\n",
    "What decisions do you have to make for training the model.  Ensure you include the following:\n",
    "\n",
    "* loss function\n",
    "* scoring criteria\n",
    "* optimization\n",
    "\n",
    "Explain why these were chosen and implement them in code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate\n",
    "\n",
    "Train the model and evaluate the results.\n",
    "\n",
    "Ensure that you print some of the Training and Validation scores that you decided upon, after each iteration / epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark integration\n",
    "\n",
    "Explain how you would train and apply this model on a large dataset that required a Spark cluster to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
